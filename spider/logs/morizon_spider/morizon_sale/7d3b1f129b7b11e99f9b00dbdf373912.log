2019-06-30 23:10:32 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: morizon_spider)
2019-06-30 23:10:32 [scrapy.utils.log] INFO: Versions: lxml 4.3.4.0, libxml2 2.9.9, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.1, Python 3.6.8 (default, Jan 14 2019, 11:02:34) - [GCC 8.0.1 20180414 (experimental) [trunk revision 259383]], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Linux-4.18.0-24-generic-x86_64-with-Ubuntu-18.04-bionic
2019-06-30 23:10:32 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'morizon_spider', 'FEED_FORMAT': 'csv', 'FEED_URI': 's3://1:1@morizon-data/%(name)s/%(time)s.csv', 'LOG_FILE': 'logs/morizon_spider/morizon_sale/7d3b1f129b7b11e99f9b00dbdf373912.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'morizon_spider.spiders', 'SPIDER_MODULES': ['morizon_spider.spiders']}
2019-06-30 23:10:32 [scrapy.extensions.telnet] INFO: Telnet Password: 34de29ab006060d2
2019-06-30 23:10:32 [py.warnings] WARNING: /usr/local/lib/python3.6/dist-packages/scrapy/utils/misc.py:144: ScrapyDeprecationWarning: Initialising `scrapy.extensions.feedexport.S3FeedStorage` without AWS keys is deprecated. Please supply credentials or use the `from_crawler()` constructor.
  return objcls(*args, **kwargs)

2019-06-30 23:10:33 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2019-06-30 23:10:33 [morizon_spider.date_utils] INFO: Found previous scraping date file...
2019-06-30 23:10:33 [morizon_spider.date_utils] INFO: Did not find previous scraping date for morizon_sale
2019-06-30 23:10:33 [twisted] CRITICAL: Unhandled error in Deferred:
2019-06-30 23:10:33 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/twisted/internet/defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/crawler.py", line 79, in crawl
    self.spider = self._create_spider(*args, **kwargs)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/crawler.py", line 102, in _create_spider
    return self.spidercls.from_crawler(self, *args, **kwargs)
  File "/usr/local/lib/python3.6/dist-packages/scrapy/spiders/__init__.py", line 51, in from_crawler
    spider = cls(*args, **kwargs)
  File "/home/antoni/private/avm-v2/morizon_spider/spiders/morizon_spider.py", line 20, in __init__
    self.previous_date = read_last_scraping_date(crawler_name=self.name)
  File "/home/antoni/private/avm-v2/morizon_spider/date_utils.py", line 27, in read_last_scraping_date
    save_obj(scraping_history_dict, path)
  File "/home/antoni/private/avm-v2/morizon_spider/date_utils.py", line 53, in save_obj
    f.write(full_string)
TypeError: a bytes-like object is required, not 'str'
